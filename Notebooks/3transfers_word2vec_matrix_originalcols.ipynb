{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Data Loading"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7024a27f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#data loading\n",
    "import pandas as pd\n",
    "\n",
    "predata = pd.read_csv(\"../data/2transfers_balanced_smorerund.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c99594",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#columns to consider for training\n",
    "predata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aea56e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#visualize the whole output\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pre Processing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42565cd9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#begin of preprocessing\n",
    "import time\n",
    "\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004e6bcc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#convert amount and accountbalance to classes and assign a word to each interval  \n",
    "import numpy as np\n",
    "#automatic labels\n",
    "import string\n",
    "\n",
    "\n",
    "class LabelCategorizer:\n",
    "    def __init__(self, base_word='cat'):\n",
    "        self.initial = 1\n",
    "        self._alphabet_index = 0\n",
    "        self.base_word = base_word\n",
    "        self.current_word = self.base_word\n",
    "        self.shift = 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'Class: Label Categorizer\\nBase word: ' + self.base_word + '\\nCurrent Word: ' + self.current_word\n",
    "\n",
    "    def get_next_word(self):\n",
    "        if self.initial:\n",
    "            self.initial = 0\n",
    "            return self.current_word\n",
    "\n",
    "        if self.shift > 0:\n",
    "            self.current_word = self.current_word[-1] + self.current_word[:-1]\n",
    "            self.shift -= 1\n",
    "        else:\n",
    "            self.current_word = self.current_word + string.ascii_lowercase[self._alphabet_index]\n",
    "            self._alphabet_index = (self._alphabet_index + 1) % len(string.ascii_lowercase)\n",
    "            self.shift = len(self.current_word) - 1\n",
    "\n",
    "        return self.current_word\n",
    "\n",
    "\n",
    "#replacement of the old columns with the new ones with classes\n",
    "def cutter(target_col, number, word, words_map):\n",
    "    #make sure that only positives are assigned an interval\n",
    "    target_col_min = max(predata[target_col].min(), 1)\n",
    "    target_col_max = max(predata[target_col].max(), 1)\n",
    "\n",
    "    bins_a = np.geomspace(float(target_col_min), float(target_col_max), num=number)\n",
    "    bins_a[0] = bins_a[0] - 1\n",
    "    bins_aux = bins_a[1:]\n",
    "    bins_aux = np.append(bins_aux, bins_a[-1] + 1)\n",
    "    bin_tuples = list(zip(bins_a, bins_aux))\n",
    "\n",
    "    bins = pd.IntervalIndex.from_tuples(bin_tuples)\n",
    "\n",
    "    #range of the intervals made\n",
    "    print(bins)\n",
    "\n",
    "    labels_a = []\n",
    "\n",
    "    a = LabelCategorizer(base_word=word)\n",
    "\n",
    "    for _ in range(number):\n",
    "        labels_a.append(a.get_next_word())\n",
    "\n",
    "    x = pd.cut(predata[target_col].to_list(), bins=bins)\n",
    "    x.categories = labels_a\n",
    "    predata[target_col] = x\n",
    "\n",
    "    for number_index in range(number):\n",
    "        words_map[labels_a[number_index]] = bins[number_index]\n",
    "\n",
    "\n",
    "#columns to apply the conversion\n",
    "columns = ['amount', 'accountbalance']\n",
    "\n",
    "#number of intervals for each column\n",
    "number_bins = [40, 40]\n",
    "\n",
    "#base words assigned to each column on columns to apply the conversion\n",
    "base_words = ['pink', 'red']\n",
    "\n",
    "#get acess to the range of the interval based on the word that appears\n",
    "values_map = {}\n",
    "\n",
    "for i in range(len(columns)):\n",
    "    cutter(columns[i], number_bins[i], base_words[i], values_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ac74c5",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#assign the word negaccount for negative values of accountbalance  \n",
    "aux = predata['accountbalance'].values\n",
    "vacc = []\n",
    "\n",
    "for elm in aux:\n",
    "    if str(elm) == 'nan':\n",
    "        vacc.append('negaccount')\n",
    "    else:\n",
    "        vacc.append(elm)\n",
    "\n",
    "predata['accountbalance'] = vacc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405df442",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#interval that a word corresponds to\n",
    "#values_map['red']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895acc61",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#convert hours to classes and assign a word to each interval  \n",
    "bins_hour = [0, 4, 8, 12, 16, 20, 24]\n",
    "\n",
    "#labels assigned to each interval\n",
    "labels_hour = ['dawn', 'earlymorning', 'morning', 'afternoon', 'dusk', 'night']\n",
    "\n",
    "predata['hour'] = list(\n",
    "    pd.cut(predata['hour'], bins=bins_hour, labels=labels_hour, retbins=True, include_lowest=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3316b32c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#convert trusted_indicator to classes and assign a word to each interval  \n",
    "bins_ti = [0.0, 0.5, 1.0]\n",
    "\n",
    "#labels assigned to each interval\n",
    "labels_ti = ['ntrusted', 'trusted']\n",
    "\n",
    "predata['trusted_indicator'] = list(\n",
    "    pd.cut(predata['trusted_indicator'], bins=bins_ti, labels=labels_ti, retbins=True, include_lowest=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6815fe4a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#add letter before number to distinguish between similar numbers from different columns\n",
    "cols = ['entity', 'reference', 'iban_orig', 'iban_dest', 'ipaddress', 'clientid', 'week']\n",
    "\n",
    "identifier = ['e', 'r', 'io', 'id', 'ip', 'c', 'w']\n",
    "\n",
    "for col in range(len(cols)):\n",
    "    predata[cols[col]] = predata[cols[col]].apply(lambda x: identifier[col] + str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3b022d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#convert binary and chain of numbers to specific words bbbb\n",
    "def apply_map(df, target_col, target_map):\n",
    "    df[target_col] = df[target_col].apply(lambda x: target_map.get(str(x)))\n",
    "\n",
    "\n",
    "cols_maps = [('is_fraud', {'0': 'nfraud', '1': 'fraud'}),\n",
    "             ('weekday', {'0': 'mon', '1': 'tue', '2': 'wed', '3': 'thu', '4': 'fri', '5': 'sat', '6': 'sun'}),\n",
    "             ('month', {'1': 'jan', '2': 'feb', '3': 'mar', '4': 'apr', '5': 'may', '6': 'jun', '7': 'jul', '8': 'aug',\n",
    "                        '9': 'sep',\n",
    "                        '10': 'oct', '11': 'nov', '12': 'dec'})]\n",
    "\n",
    "for comb in cols_maps:\n",
    "    apply_map(predata, comb[0], comb[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c540cd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#make fraud column as the center column\n",
    "new_order = ['canal', 'operativa', 'clientid', 'entity', 'reference', 'trusted_indicator', 'iban_orig', 'iban_dest',\n",
    "             'amount',\n",
    "             'is_fraud', 'accountbalance', 'ipaddress', 'browser_family', 'os_family', 'hour', 'week', 'weekday',\n",
    "             'month',\n",
    "             'device']\n",
    "\n",
    "predata = predata[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add62c42",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#select data for train and test  \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#target column\n",
    "y = predata['is_fraud']\n",
    "\n",
    "#train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(predata, y, stratify=y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db10e74",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#for entering the model\n",
    "sentences = X_train.to_numpy()\n",
    "sentences_aux = [list(curr) for curr in sentences]\n",
    "sentences_series = pd.Series(sentences_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ad421a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#for the test metrics\n",
    "X_test_np = X_test.copy()\n",
    "del X_test_np['is_fraud']\n",
    "\n",
    "sentences_np_test = X_test_np.to_numpy()\n",
    "sentences_aux_np_test = [list(curr) for curr in sentences_np_test]\n",
    "sentences_series_np_test = pd.Series(sentences_aux_np_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba911c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#for the train metrics\n",
    "X_train_np = X_train.copy()\n",
    "del X_train_np['is_fraud']\n",
    "\n",
    "sentences_np_train = X_train_np.to_numpy()\n",
    "sentences_aux_np_train = [list(curr) for curr in sentences_np_train]\n",
    "sentences_series_np_train = pd.Series(sentences_aux_np_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a979a1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#get size of the corpus \n",
    "token_count = sum([len(sentence) for sentence in sentences_series])\n",
    "print(\"This corpus contains {} tokens\".format(token_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8a3530",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#end of preprocessing\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee98245",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#begin of training\n",
    "begin = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1640ad3b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#callback to print loss after each epoch\n",
    "import gensim.models.word2vec as w2v\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "\n",
    "class MyGensimCallback(CallbackAny2Vec):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.loss_to_be_subed = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        loss_now = loss - self.loss_to_be_subed\n",
    "        self.loss_to_be_subed = loss\n",
    "        print('Loss after epoch {}: {}'.format(self.epoch, loss_now))\n",
    "\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ae36bf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#inicialization and training word2vec - put equal to grid search\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "def training(sentences, cycles, dim, window, sample, negative, exponent, alpha, min_alpha):\n",
    "    model = w2v.Word2Vec(\n",
    "        sg=1,  #skip-gram - fixed\n",
    "        workers=multiprocessing.cpu_count(),  #use all cores - fixed\n",
    "        vector_size=dim,  #dimension of the embedding space - change\n",
    "        window=window,  #words befores and after the center word - change\n",
    "        sample=sample,  #whithout subsampling - change\n",
    "        min_count=1,  #use every word - fixed\n",
    "        negative=negative,  #noise-words - change\n",
    "        hs=0,  #negative sampling\n",
    "        ns_exponent=exponent,  #exponent to shape negative sampling - change\n",
    "        alpha=alpha,  #initial learning rate - change\n",
    "        min_alpha=min_alpha  #final learning rate - change\n",
    "    )\n",
    "\n",
    "    #vocabulary creation\n",
    "    model.build_vocab(sentences)\n",
    "\n",
    "    #model training\n",
    "    model.train(sentences, epochs=cycles, total_examples=model.corpus_count, compute_loss=True,\n",
    "                callbacks=[MyGensimCallback()])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "#model creation\n",
    "model = training(sentences_series, 5, 5, 9, 0, 5, 0.75, 0.025, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04bbcf3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#info about the trained model \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#update z - dictionary that saves the word and its position\n",
    "def refresh_z(model, k, missingw):\n",
    "    #looks for the missing word starting from the bottom\n",
    "    for i in range(len(model.wv.index_to_key) - 1, 0, -1):\n",
    "\n",
    "        #assigns the new position of the missing word in the vocabulary\n",
    "        if model.wv.index_to_key[i] == missingw:\n",
    "            k[missingw] = i\n",
    "\n",
    "            #from the moment the word is found returns the new dictionary\n",
    "            return k\n",
    "\n",
    "    return k"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#update probv - vector with the parameters of a transaction\n",
    "\n",
    "def refresh_probv(model, cid):\n",
    "    #obtain the representative vector of the clientid\n",
    "    civ = model.wv.get_vector(cid)\n",
    "\n",
    "    #multiplication of the clientid vector by the decode matrix (M2)\n",
    "    m2 = model.syn1neg\n",
    "    #vector of len = vocab_size\n",
    "    vout = np.dot(civ, m2.T)\n",
    "\n",
    "    #apply softmax to the previous vector to obtain the conditional probabilities\n",
    "    probv = softmax(vout)\n",
    "\n",
    "    return probv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#prediction method\n",
    "from scipy.special import softmax\n",
    "\n",
    "def predict(model, X, threshold, verbose1, verbose2):\n",
    "    #save the predictions made by the model in a list\n",
    "    predictions = []\n",
    "\n",
    "    #TODO: ????\n",
    "    k = {}\n",
    "    missingw = \"\"\n",
    "\n",
    "    z = refresh_z(model, k, missingw)\n",
    "\n",
    "    #for each transaction (eval_row)\n",
    "    for eval_row in X:\n",
    "\n",
    "        #print transaction parameters if verbose1 True\n",
    "        if verbose1:\n",
    "            print(eval_row)\n",
    "\n",
    "        #cid is always in position 2 of the array\n",
    "        curr_cid = eval_row[2]\n",
    "\n",
    "        #if curr_cid is not known\n",
    "        if curr_cid not in model.wv.index_to_key:\n",
    "            #update model\n",
    "            model.build_vocab([[curr_cid]], update=True)\n",
    "            #update z\n",
    "            z = refresh_z(model, k, missingw)\n",
    "\n",
    "        else:\n",
    "            #for each sentence_series creates a current list\n",
    "            curr = []\n",
    "\n",
    "            #filter the parameters associated with the transaction made by the specific clientid (civ)\n",
    "            for x in eval_row:\n",
    "                if x != curr_cid:\n",
    "                    if x in model.wv.index_to_key:\n",
    "                        curr.append(z[x])\n",
    "\n",
    "                    else:\n",
    "                        #if the word is not known\n",
    "                        #update model\n",
    "                        model.build_vocab([[x]], update=True)\n",
    "\n",
    "                        #update z\n",
    "                        z = refresh_z(model, k, missingw)\n",
    "                        #TODO: Problem KeyError: 'nbe'\n",
    "                        curr.append(z[x])\n",
    "\n",
    "            #sum each value on the array to obtain the final probability\n",
    "            probv = refresh_probv(model, curr_cid)\n",
    "            fprob = sum(probv[curr])\n",
    "\n",
    "            #print results if verbose True\n",
    "            if verbose2:\n",
    "                print(f\"Array content: {probv[curr]} \\t Sum: {fprob} \\n\")\n",
    "\n",
    "            #convert the values to binary and append to predictions\n",
    "            if fprob < threshold:\n",
    "                predictions.append(0)\n",
    "            else:\n",
    "                predictions.append(1)\n",
    "\n",
    "    return predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b4c33",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#grid-search\n",
    "#save results\n",
    "import sys\n",
    "import itertools\n",
    "\n",
    "old_stdout = sys.stdout\n",
    "log_file = open(\"results.log\", \"w\")\n",
    "sys.stdout = log_file\n",
    "\n",
    "#create a dictionary for the hyperparameters that are going to vary\n",
    "cycles = [5, 10, 50, 100]\n",
    "dim = [5, 50, 150, 300]  #[2, 5, 10, 50, 150, 300]\n",
    "window = [2, 5, 9]  #[1 - 9]  \n",
    "negative = [0, 5, 10, 20]  #[0, 5, 10, 15, 20]\n",
    "exponent = [-1, -0.75, 0, 0.75,\n",
    "            1]  #1.0 samples exactly in proportion to the frequencies, 0.0 samples all words equally, while a negative value samples low-frequency words more than high-frequency words. The 0.75 was chosen by the original Word2Vec paper. In https://arxiv.org/abs/1804.04212, Caselles-Dupré, Lesaint, & Royo-Letelier suggest that other values may perform better for recommendation applications\n",
    "alpha = [0.015, 0.025, 0.035]\n",
    "min_alpha = [0.0001, 0.0006]\n",
    "sample = [0, 0.001, 0.00001]\n",
    "\n",
    "#can try sg = 0 /// hs = 1 (leads to negative = 0)\n",
    "\n",
    "#train the model with the dictionary\n",
    "for (c, d, w, n, e, a, m, s) in itertools.product(cycles, dim, window, negative, exponent, alpha, min_alpha, sample):\n",
    "    curr_model = training(sentences_series, cycles=c, dim=d, window=w, negative=n,\n",
    "                          exponent=e, alpha=a, min_alpha=m, sample=s)\n",
    "\n",
    "    #metrics for each combination\n",
    "    predict(curr_model, sentences_series_np_train, 0.5, verbose1=False, verbose2=False)\n",
    "\n",
    "#save results \n",
    "sys.stdout = old_stdout\n",
    "log_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea0e6c7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#words in the vocabulary\n",
    "#model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b1d6f3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#model's memory consuming members with their size in bytes\n",
    "#model.estimate_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98c17be",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#saving the model\n",
    "#model.save(r'C:/Users/BeatrizCarvalho/OneDrive - Closer Consultoria Lda/Documents/Entangled-Spaces/Datasets/3transfers_word2vec_matrix_originalcols.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7372fd83",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#end of training\n",
    "end = time.time()\n",
    "print(f\"Training time: {end - begin}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23261498",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#option 1\n",
    "#python 3transfers_word2vec_matrix_originalcols_saving.py &> results.txt\n",
    "\n",
    "\n",
    "#option 2\n",
    "# def fprint(output):\n",
    "#     print output\n",
    "#     with open(\"somefile.txt\", \"a\") as f:\n",
    "#         f.write(\"{}\\n\".format(output))\n",
    "\n",
    "\n",
    "#option 3\n",
    "# from contextlib import redirect_stdout\n",
    "#\n",
    "# with open('results.log', 'w') as f:\n",
    "#     with redirect_stdout(f):\n",
    "#         print('generating')\n",
    "# the rest of your code or main function goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c874e8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#------------------------------------------probability vector for a client----------------------------------------------------#\n",
    "\n",
    "#weight matrices\n",
    "m1 = model.wv.vectors\n",
    "m2 = model.syn1neg  #negative sampling\n",
    "#m2 = model.syn1       #hierarchical-softmax "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1773c325",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#m2 shape\n",
    "m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb36784",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#apply the prediction method for the train set\n",
    "predict(model, sentences_series_np_train, 0.5, verbose1=True, verbose2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d360ed11",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#true values\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeec16e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#convert true values in train set to binary\n",
    "y_train = [1 if elem == \"fraud\" else 0 for elem in y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7f94ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#metrics for the train set\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, matthews_corrcoef, confusion_matrix, precision_recall_curve\n",
    "\n",
    "#accuracy\n",
    "accuracy = accuracy_score(y_train, predict(model, X_train_np.values, 0.5, verbose1=False, verbose2=False))\n",
    "print('accuracy: {}'.format(accuracy))\n",
    "\n",
    "#precision, recall, f-score\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_train, predict(model, X_train_np.values, 0.5,\n",
    "                                                                                      verbose1=False, verbose2=False),\n",
    "                                                                     average='micro')\n",
    "\n",
    "#precision - ratio tp / (tp + fp) - ability not to label a negative sample as positive\n",
    "print('precision: {}'.format(precision))\n",
    "\n",
    "#recall - ratio tp / (tp + fn) - ability to find all the positive samples - best is 1, worst is 0\n",
    "print('recall: {}'.format(recall))\n",
    "\n",
    "#fscore - weighted harmonic mean of the precision and recall - best is 1, worst is 0\n",
    "print('fscore: {}'.format(fscore))\n",
    "\n",
    "#matthews correlation coefficient - measure of the quality of binary classifications\n",
    "#can be used even if the classes are of very different sizes - is in essence a correlation coefficient between -1 and +1\n",
    "#+1 means perfect prediction, 0 an average random prediction, -1 an inverse prediction\n",
    "mcc = matthews_corrcoef(y_train, predict(model, X_train_np.values, 0.5, verbose1=False, verbose2=False))\n",
    "print('mcc: {}'.format(mcc))\n",
    "\n",
    "#g-mean - squared root of the product of the sensitivity and specificity - best is 1, worst is 0\n",
    "print('G-mean:', (geometric_mean_score(y_train, predict(model, X_train_np.values, 0.5, verbose1=False, verbose2=False),\n",
    "                                       average='micro')))\n",
    "\n",
    "#specificity - ability to predict true negatives of each available category - recall of the negative class\n",
    "specifity = tn / (tn + fp)\n",
    "print('specifity: {}'.format(specifity))\n",
    "\n",
    "#sensitivity - ability to predict true positives of each available category = recall\n",
    "#break\n",
    "\n",
    "#confusion matrix    \n",
    "print(confusion_matrix(y_train, predict(model, X_train_np.values, 0.5, verbose1=False, verbose2=False)))\n",
    "\n",
    "#true positives, false positives, true negatives, false negatives\n",
    "tn, fp, fn, tp = confusion_matrix(y_train,\n",
    "                                  predict(model, X_train_np.values, 0.5, verbose1=False, verbose2=False)).ravel()\n",
    "\n",
    "#true negatives\n",
    "print('true negatives: {}'.format(tn))\n",
    "\n",
    "#false positives\n",
    "print('false positives: {}'.format(fp))\n",
    "\n",
    "#false negatives\n",
    "print('false negatives: {}'.format(fn))\n",
    "\n",
    "#false positives\n",
    "print('true positives: {}'.format(tp))\n",
    "\n",
    "#error rate\n",
    "error_rate = 1 - accuracy\n",
    "print('error rate: {}'.format(error_rate))\n",
    "\n",
    "#precision-recall curve - compute precision-recall pairs for different probability thresholds\n",
    "print(precision_recall_curve(y_train, predict(model, X_train_np.values, 0.5, verbose1=False, verbose2=False)))\n",
    "\n",
    "#roc curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_train,\n",
    "                                         predict(model, X_train_np.values, 0.5, verbose1=False, verbose2=False))\n",
    "\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='Word2vec')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabb28cf",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#apply the prediction method for the test set\n",
    "predict(model, X_test_np_test, 0.5, verbose1=True, verbose2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ce881a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#true values\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180bfb6c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#convert true values in train set to binary\n",
    "y_test = [1 if elem == \"fraud\" else 0 for elem in y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a0825f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#metrics for the test set \n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, matthews_corrcoef, confusion_matrix, precision_recall_curve\n",
    "\n",
    "#accuracy\n",
    "accuracy = accuracy_score(y_test, predict(model, X_test_np_test, 0.5, verbose1=False, verbose2=False))\n",
    "print('accuracy: {}'.format(accuracy))\n",
    "\n",
    "#precision, recall, f-score\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test,\n",
    "                                                                     predict(model, X_test_np_test, 0.5, verbose1=False,\n",
    "                                                                             verbose2=False), average='micro')\n",
    "\n",
    "#precision - ratio tp / (tp + fp) - ability not to label a negative sample as positive\n",
    "print('precision: {}'.format(precision))\n",
    "\n",
    "#recall - ratio tp / (tp + fn) - ability to find all the positive samples - best is 1, worst is 0\n",
    "print('recall: {}'.format(recall))\n",
    "\n",
    "#fscore - weighted harmonic mean of the precision and recall - best is 1, worst is 0\n",
    "print('fscore: {}'.format(fscore))\n",
    "\n",
    "#matthews correlation coefficient - measure of the quality of binary classifications\n",
    "#can be used even if the classes are of very different sizes - is in essence a correlation coefficient between -1 and +1\n",
    "#+1 means perfect prediction, 0 an average random prediction, -1 an inverse prediction\n",
    "mcc = matthews_corrcoef(y_test, predict(model, X_test_np_test, 0.5, verbose1=False, verbose2=False))\n",
    "print('mcc: {}'.format(mcc))\n",
    "\n",
    "#g-mean - squared root of the product of the sensitivity and specificity - best is 1, worst is 0\n",
    "print('G-mean:', (\n",
    "    geometric_mean_score(y_test, predict(model, X_test_np_test, 0.5, verbose1=False, verbose2=False), average='micro')))\n",
    "\n",
    "#specificity - ability to predict true negatives of each available category - recall of the negative class\n",
    "specifity = tn / (tn + fp)\n",
    "print('specifity: {}'.format(specifity))\n",
    "\n",
    "#sensitivity - ability to predict true positives of each available category = recall\n",
    "#break\n",
    "\n",
    "#confusion matrix    \n",
    "print(confusion_matrix(y_test, predict(model, X_test_np_test, 0.5, verbose1=False, verbose2=False)))\n",
    "\n",
    "#true positives, false positives, true negatives, false negatives\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, predict(model, X_test_np_test, 0.5, verbose1=False, verbose2=False)).ravel()\n",
    "\n",
    "#true negatives\n",
    "print('true negatives: {}'.format(tn))\n",
    "\n",
    "#false positives\n",
    "print('false positives: {}'.format(fp))\n",
    "\n",
    "#false negatives\n",
    "print('false negatives: {}'.format(fn))\n",
    "\n",
    "#false positives\n",
    "print('true positives: {}'.format(tp))\n",
    "\n",
    "#error rate\n",
    "error_rate = 1 - accuracy\n",
    "print('error rate: {}'.format(error_rate))\n",
    "\n",
    "#precision-recall curve - compute precision-recall pairs for different probability thresholds\n",
    "print(precision_recall_curve(y_test, predict(model, X_test_np_test, 0.5, verbose1=False, verbose2=False)))\n",
    "\n",
    "#roc curve\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, predict(model, X_test_np_test, 0.5, verbose1=False, verbose2=False))\n",
    "\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name='Word2vec')\n",
    "display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa92c47",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#save the threshold and the ratio in a list\n",
    "def thres_numberf():\n",
    "    threshold = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "    ratio = []\n",
    "\n",
    "    for thresh in threshold:\n",
    "        #assign to a current variable the prediction result\n",
    "        curr = predict(model, X_test_np_test, thresh, verbose1=False, verbose2=False)\n",
    "\n",
    "        #ratio of the number of detected frauds per the number of real frauds\n",
    "        ratio.append(sum(curr) / sum(y_test))\n",
    "\n",
    "    return threshold, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff05a519",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#plot the threshold vs ratio (number of detected frauds/number of real frauds)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#assign the values to plot\n",
    "thresh, goal = thres_numberf()\n",
    "\n",
    "plt.plot(thresh, goal, 'b-')\n",
    "plt.xlabel('threshold')\n",
    "plt.ylabel('#frauds detected/#real frauds')\n",
    "\n",
    "#save to csv\n",
    "thresh_ratio = np.column_stack((thresh.flatten(), goal.flatten()))\n",
    "np.savetxt('threshold_ratio.csv', thresh_ratio, goal, delimiter=',')\n",
    "\n",
    "#log scale\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#plt.savefig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5ad885",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#---------------------------------------------------density matrix------------------------------------------------------------#\n",
    "\n",
    "#product of the matrices\n",
    "mproduct = np.matmul(m1, m2.T)\n",
    "mproduct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecaf72a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#apply softmax to obtain a matrix with conditional probabilities\n",
    "conditional_probs = softmax(mproduct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91ba786",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#save density matrix \n",
    "\n",
    "#option 1\n",
    "#np.savetxt('3transfers_word2vec_matrix_originalcols_density_matrix.csv', conditional_probs, delimiter = ',')\n",
    "\n",
    "#option 2\n",
    "#pd.DataFrame(conditional_probs).to_csv(\"3transfers_word2vec_matrix_originalcols_density_matrix.csv\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac893603",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#confirm that softmax sum is 1\n",
    "conditional_probs.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7c6465",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#maximum value of the conditional probabilities\n",
    "np.max(conditional_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7fd863",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#minimum value of the conditional probabilities\n",
    "np.min(conditional_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963e0b6f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#visualize the 1st 10 lines and the last 10 lines of the density matrix\n",
    "\n",
    "#1st 10 lines\n",
    "conditional_aux = conditional_probs[:10].copy()\n",
    "\n",
    "#last 10 lines\n",
    "conditional_aux = np.concatenate((conditional_aux, conditional_probs[-10:].copy()))\n",
    "\n",
    "#display setting\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cd964d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#shape of the compressed density matrix \n",
    "conditional_aux.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac91f8aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#print the compressed conditional probabilities matrix\n",
    "print('\\n'.join(['\\t'.join([str(cell) for cell in row]) for row in conditional_aux]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daf4fdd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------eigenvalues-----------------------------------------------------------------#\n",
    "\n",
    "#eingenvalues of the square matrix before softmax (w has the eigenvalues and v the eigenvectors)\n",
    "w, v = np.linalg.eig(mproduct)  #mproduct is an array of arrays\n",
    "\n",
    "#separate real and imaginary parts of the eigenvalues\n",
    "x = w.real  #array\n",
    "\n",
    "y = w.imag  #array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acea2653",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#eigenvalues\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c25cf1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#eigenvalues plot for the several vector sizes - square of the numbers in mproduct (product of the matrices before softmax)  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#plot complex numbers\n",
    "def plot_eigenvalues(model, vec_size):\n",
    "    x_r = np.square(x)\n",
    "    y_i = np.square(y)\n",
    "\n",
    "    plt.plot(x_r, 'b-')\n",
    "    plt.ylabel('Imaginary')\n",
    "    plt.xlabel('Real')\n",
    "\n",
    "    #plt.ylim(0, 250e6)\n",
    "    #plt.xlim(0, 15)\n",
    "\n",
    "    fig_name = \"vec_size_\" + vec_size + \"_best_comb.png\"\n",
    "    plt.savefig(fig_name)\n",
    "\n",
    "    return x_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73943d5a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#train the model with the optimized parameters for different vector sizes  \n",
    "\n",
    "#dictionary of results\n",
    "result_dic = {}\n",
    "\n",
    "#vector sizes to try\n",
    "vec_sizes = [3, 4]\n",
    "\n",
    "#train the model\n",
    "for curr_vec in vec_sizes:\n",
    "    curr_model = w2v.Word2Vec(\n",
    "        sg=1,  #skip-gram\n",
    "        workers=multiprocessing.cpu_count(),  #use all cores\n",
    "        vector_size=curr_vec,  #dimension of the embedding space\n",
    "        window=9,  #words befores and after the center word\n",
    "        sample=0,  #whithout subsampling\n",
    "        min_count=1,  #use every word\n",
    "        negative=5,  #noise-words\n",
    "        hs=0,  #negative sampling\n",
    "        ns_exponent=0,  #exponent to shape negative sampling\n",
    "        alpha=0.025,  #initial learning rate\n",
    "        min_alpha=0.0001  #final learning rate\n",
    "    )\n",
    "\n",
    "    #vocabulary creation\n",
    "    model.build_vocab(sentences_series)\n",
    "\n",
    "    #model training\n",
    "    model.train(sentences_series, epochs=5, total_examples=model.corpus_count, compute_loss=True,\n",
    "                callbacks=[MyGensimCallback()])\n",
    "\n",
    "    curr_vec_size = 0\n",
    "    #save results in the dictionary \n",
    "    result_dic[curr_vec_size] = plot_eigenvalues(curr_model, curr_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873e5396",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#option 1 - export result_dic and plot in excel\n",
    "#convert the dictionary to dataframe\n",
    "result_dic = pd.DataFrame(data=result_dic, index=[0])\n",
    "result_dic = (result_dic.T)\n",
    "result_dic.to_excel('3transfers_word2vec_matrix_originalcols_eingenvalues.xlsx')\n",
    "\n",
    "#option 2 - plot result_dic with matplotlib\n",
    "plt.plot(list(result_dic.keys()), list(result_dic.values()))\n",
    "plt.legend(['3', '4'], loc='upper left')\n",
    "plt.savefig('3transfers_word2vec_matrix_originalcols_eingenvalues.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2126ea1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------operations with word vectors-------------------------------------------------------#\n",
    "\n",
    "#topn most similar words \n",
    "model.wv.most_similar('fraud')[:10]\n",
    "\n",
    "#another alternative - same output\n",
    "#model.wv.similar_by_word('fraud', topn = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a830a6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#word from the word's list most similar to the 1st word given\n",
    "model.wv.most_similar_to_given('c29814', ['windows', 'c29814'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98963647",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#cosine similarity between two words\n",
    "model.wv.similarity('nfraud', 'windows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230ac7b4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#cosine similarity between two sets of words\n",
    "model.wv.n_similarity(['pc', 'windows'], ['tablet', 'android'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8b4e5d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#cosine similarities between one vector and a set of other vectors\n",
    "c = np.array([0.15340006, 0.2575258, 0.94247705, 0.27604532, -0.5088184])\n",
    "d = np.array([[0.15340006, 0.2575258, 0.94247705, 0.27604532, -0.5088185],\n",
    "              [0.15340006, 0.2575258, 0.94247705, 0.27604532, -0.5088186],\n",
    "              [0.15340006, 0.2575258, 0.94247705, 0.27604532, -1.5088186]])\n",
    "\n",
    "model.wv.cosine_similarities(c, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b859c6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#cosine distances from given word or vector to all words in other_words\n",
    "#if other_words is empty it returns the distance between word_or_vectors and all words in vocab\n",
    "model.wv.distances('pc', other_words=('tablet', 'mobile'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb9d576",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#cosine distance between two words\n",
    "model.wv.distance('nfraud', 'windows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6736b9a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#positive contribute positively towards the similarity and negative keys negatively\n",
    "#cosine similarity\n",
    "model.wv.most_similar(positive=['pc', 'windows'], negative=['android'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85de316f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#topn most similar words using the multiplicative combination objective\n",
    "#additional positive or negative examples contribute to the numerator or denominator respectively\n",
    "#a single positive example is the same as most_similar()\n",
    "model.wv.most_similar_cosmul(positive=['pc', 'windows'], negative=['android'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f821f4a5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#relative cosine similarity between two words given topn similar words\n",
    "#1st word - word for which we have to look topn similar word\n",
    "#2nd word - word for which we are evaluating relative cosine similarity with the 1st word\n",
    "model.wv.relative_cosine_similarity('windows', 'c29814')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804bbbb4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#word from the given list that doesn’t go with the others\n",
    "model.wv.doesnt_match(['nbe', 'trfint', 'e3', 'r3', 'ntrusted', 'io4', 'id875448', 'ueabbl', 'pinka', 'ip17218224251',\n",
    "                       'nmobile', 'ntablet', 'pc', 'ntouch', 'nbot', 'chrome', 'windows', 'ncd1', 'nid2796', 'niod1',\n",
    "                       'nidd0',\n",
    "                       'ctd690877', 'idtd-1', 'cdarbe', 'eyagbr', 'ncid1', 'nciod1', 'ncidd1', 'd20190814', 'h0',\n",
    "                       'cfi1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c0dd32",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#topn most similar keys\n",
    "#when topn is None the similarities for all words are returned as a one-dimensional numpy array with the size of the vocabulary\n",
    "model.wv.similar_by_key('windows', topn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501c5692",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#topn most similar keys by vector\n",
    "a = np.array([0.15340006, 0.2575258, 0.94247705, 0.27604532, -0.5088185])\n",
    "model.wv.similar_by_vector(a, topn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c7f65b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#rank of the distance of word2 from word1 in relation to distances of all words from the word1\n",
    "model.wv.rank('c29814', 'windows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83894c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#rank the given words by similarity to the centroid of all the words\n",
    "model.wv.rank_by_centrality(['windows', 'c29814'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}